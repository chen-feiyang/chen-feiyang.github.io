<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>regression on Feiyang Chen&#39;s Blog</title>
    <link>https://chen-feiyang.github.io/tags/regression/</link>
    <description>Recent content in regression on Feiyang Chen&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 28 Jul 2019 22:58:19 +0800</lastBuildDate>
    
	<atom:link href="https://chen-feiyang.github.io/tags/regression/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Kaggle之House Prices: Advanced Regression Techniques竞赛项目总结</title>
      <link>https://chen-feiyang.github.io/posts/hpart/</link>
      <pubDate>Sun, 28 Jul 2019 22:58:19 +0800</pubDate>
      
      <guid>https://chen-feiyang.github.io/posts/hpart/</guid>
      <description> 项目介绍： 竞赛数据集为Ames Housing dataset，是一个房价销售的数据集，需据此预测房屋销售价格，误差度量要求采用实际售价与预测售价的对数的均方根误差（RMSE），在此度量标准下，关注的不是实际售价和预测售价的差值，而是其比值。
项目成绩： 我的迄今最好成绩是0.10616，也就是实际售价与预测售价之比平均约为e的0.10616次方（约等于1.1120），目前排名29/4413。成绩见于https://www.kaggle.com/c/house-prices-advanced-regression-techniques/leaderboard，名称feiyang0chen1。
项目心得体会：  若未认真理解项目需求，采用不经对数转换的RMSE，也许成绩停留在0.15；若不经对数转换，采用RMSLE（对数均方根误差），也许误差停留在0.14。显然损失函数决定优化的方向，这两种情况均因偏离项目要求的优化方向难以取得更好表现。 单个模型最好的是线性回归，发现对严重偏离正态分布的特征进行转换可提高成绩。 线性模型需要特征矩阵之间线性无关，PCA可以做到，但将过滤掉一些有用信息。若不采用PCA，可引入正则化项抑制线性模型特征对应的系数，这也是一种特征选择的方法，视正则化项的不同分别为lasso、ridge、elasticnet。 分类变量最理想的情况应该平衡，查阅文献，对于高分化分类变量（即含有很多分类，一些分类含有极少的数据点rare category），应采用target encoding而不是onehot encoding，target encoding可以采取忽视rare category的策略以减少杂讯。本案例分类变量虽不是特别高分化，但某些分类所含的数据点只有6个，应具有类似特点。但是发现target encoding没有提高成绩。 数据集含有较多的缺失数据，对于一些特征列，有相互印证的数据列比较好填补缺失值，没有这些印证信息的缺失数据，可采用删除数据点、删除特征列，或补入均值、中值、众值、回归（分类）等，回归（分类）又涉及到具体该采用什么模型什么特征列等，变数很多，查阅文献暂没有绝对优势的策略。补入虽然补充了信息但也引入了杂讯，一般认为补充中值、众值将使模型更鲁棒。 离群值，检索数据集，含有一个特征名为MSZoning，是标注地产商业性质的分类变量。通过分析此变量，发现在大多数特征点为各种住宅地产，极少数是工业或其他地产。自然想到有些数据点为离群值。而且，常识判断，与总售价最相关的是总使用面积GrLivArea，分析相关性也证明了这一点。根据总使用面积和总售价的联合分布，有些数据点是明显偏离的。单变量离群值分析，可假设此变量服从某分布，再排除概率小于某值比如1%的范围区间内的值，但这种判断方法应无益于机器学习问题。机器学习中可将模型残差大于一定值的数据点视为域外值，但选择什么特征建立模型、选择什么模型、残差大于多少判断为残差目前似乎没有公论，只能视具体情况试验。而且，排除过多数据点将使预测数据集的分布过多偏离训练数据。这违背机器学习的根本假设即数据同分布。 若特征数量较少，可直观地判断欠拟合和过拟合；当纬度较大时，可通过判断验证数据集上的表现来减小过拟合，但仍不能根绝。异源的模型组合可进一步减少过拟合以提高表现，假设两个模型的预测不同，具体到某一数据点，若真实值不在两模型预测值之间，此点模型融合的表现将是单个模型表现的某权值组合的加权平均；但也很可能实际值处在两模型预测值之间，此点模型融合的表现将优于单个模型，所以模型融合较大概率对表现有提升，我的模型的明显提升也正是来源于此，几个RMSE在0.11上下的模型平均后RMSE为0.106，优于任一单个模型的表现。可任意武断假设模型的权值，这在sklearn里面可通过VotingRegressor实现。当然模型融合的权值也是可以通过学习得到的，mlxtend中便捷函数StackingRegressor，设置meta_regressor为线性模型并线性模型设置fit_intercept=False可学习权值。当然meta_regressor也可不是线性模型甚至融合模型让基础模型的特征重新参与训练，这正是堆叠stack的含义。基础模型的预测作为特征重新参与建模将造成过拟合/泄露，可以让基础模型的预测来自k折后的k个训练数据形成的模型的折外数据点的预测（out-of-fold predictions），这可通过StackingCVRegressor实现。 关于模型的特征数量和特征选择：模型的特征数量影响计算速度并模型复杂度，过度复杂的模型容易产生过拟合。分类变量的编码方式将改变潜在特征数，lasso、基于树的模型等可自动选择特征。 最终模型取自特定补充缺失值策略、分类变量编码策略、排除离群值策略、PCA、基础模型选择、模型融合策略的组合，很难相信这是最优解，但结果尚可。 鉴于我的模型表现与排行榜仍有较大差距，猜测也许数据更适于采用某一非线性模型。可实现非线性的模型主要有：1基于树的模型，2线性模型采用非线性核函数，3.深度模型采用非线性激活函数。基于树的模型如决策树、提升等不能取得优于线性模型的表现是因为训练数据点较少时基于树的模型将不够顺滑，这将使预测表现不够好。当训练数据点较少时候，以决策树为例，若训练数据点含n个独特值，那么模型的预测值也将不外乎这n个独特值。提升算法的情况类似，虽然权值将导致预测的可能取值稍微增加，但仍不可避免比较稀疏，这将导致在非训练数据上表现不佳。而线性模型采用非线性核函数将不产生类似基于树模型同类的稀疏，但是，其非线性是不可学习的，只能作为高参调参，而且非线性高参可调弹性比较小，比方采用多项式核，其次数只能为整数。深度学习可学习非线性本身，也许进一步提升模型性能的方向在此。 以上体会基于此项目的一些经验或我的一些主观猜测，错漏之处在所难免，应进一步夯实。  </description>
    </item>
    
    <item>
      <title>Dont_overfit_ii</title>
      <link>https://chen-feiyang.github.io/posts/dont_overfit_ii/</link>
      <pubDate>Fri, 12 Apr 2019 17:02:22 +0800</pubDate>
      
      <guid>https://chen-feiyang.github.io/posts/dont_overfit_ii/</guid>
      <description>2019/4/9开始kaggle的Don&#39;t Overfit! II竞赛，竞赛含250条训练数据，需要据此预测19.8k条数据的目标值。特征300个，目标值为0-1变量，训练样本含正样本160条，负样本90条。
kaggle的Don&#39;t Overfit! II竞赛。
显然，此竞赛的特点是小样本和不平衡样本。
关于小样本的解决参考4；关于不平衡数据参考2。
注意：不平衡数据不会造成过拟合，不平衡数据倾向于归入大分类的误分类，AUCROC是度量这种误分类的度量函数。？？？？？？
关于不平衡：
按参考2，解决不平衡学习问题的五种方法包括： 1. Up-sample the minority class对少数分类升采样 2. Down-sample the majority class对多数分类降采样 3. Change your performance metric改变度量函数 4. Penalize algorithms (cost-sensitive training)惩罚算法（即代价敏感训练） 5. Use tree-based algorithms采用基于树的算法
COSTCLA、costsensitive包可实现方法4。
按TOM FAWCETT，分类问题不能简单地预测标签。因为但： 1. 预测标签浪费很多信息，概率才是更重要的。 2. 虽然很多分类学习器都有预测概率这个功能，但很可能其简单以0.5作为阈值划分分类标签的依据。由于算法、数据不平衡和训练测试数据集标签比例不均衡等原因，此模型所谓的”概率“是不准确的，所以不可以简单以0.5作概率阈值。 3. 在概率不准情况下需要选择合适的概率阈值作为划分标签的依据。 4.也可以校准，在sklearn中有sklearn.calibration.CalibratedClassifierCV。TOM FAWCETT先生的意思我并没有叙述准确，详见其博客（参考4、5）。
那么将train分成tra、val，选取学习器比如逻辑回归，高参由tra进行cv获取，运用全部tra并cv获取的高参训练模型。查看模型对tra和val的aucroc，比较tra和val的aucroc，若接近说明没有过拟合，可用这个模型对test进行预测。class_weight需使weigh乘以分类样本数得到的乘积平衡，在sklearn可选‘balanced’。其他包应根据分类样本数自己设定。
第一步选择逻辑回归，重复上行过程，这个结果作为基础，其他学习器的结果需好于此学习器。
参考：
 1.Investigation on handling Structured &amp;amp; Imbalanced Datasets with Deep Learning； 2.EXPLAINERS TUTORIALS__How to Handle Imbalanced Classes in Machine Learning； 3.Cost-sensitive 分类算法——综述与实验； 4.</description>
    </item>
    
    <item>
      <title>Kaggle之Store item demand forecasting challenge竞赛项目总结</title>
      <link>https://chen-feiyang.github.io/posts/store_item_demand_forecasting_challenge/</link>
      <pubDate>Sun, 03 Mar 2019 22:06:58 +0800</pubDate>
      
      <guid>https://chen-feiyang.github.io/posts/store_item_demand_forecasting_challenge/</guid>
      <description>1.项目情况 kaggle的Store Item Demand Forecasting Challenge竞赛， 有2013年初到2017年末10个商店、50种货物每日销量情况，预测2018年头3个月这些商店、货物的每日销售情况。竞赛要求结果采用SMAPE度量。 $$SMAPE=100 \text{%} \frac{1}{n} \sum_{i=1}^{n} \frac{|A_i-F_i|}{(|A_i|+|F_i|)/2}$$ $A_i$代表第i个样本的真实值，$F_i$代表第i个样本的预测值。
2.项目成绩 以下代码采用2014年、2015年和2016年数据用于训练，2017年数据用于验证，模型采用损失函数RMSE，度量函数SMAPE。得到训练smape约12.30[11]，2017年smape为11.860766606767626[12]，2014年第一季度smape为14.645917711865364[3]，2015年第一季度smape为14.091883155407277[4]，2016年第一季度smape为13.476791353148277[5]，2017年第一季度smape为13.301776762020786[6]。据此推断2018年第一季度smape约12.5846141148，与竞赛最优成绩12.58015相当，可惜不在竞赛时段，无法最终验证。依据如下：
损失函数采用RMSE， $$RMSE=\sqrt{\frac{1}{n} \sum_{i=1}^{n} {(A_i-F_i)}^{2}}$$ 其关注的是绝对误差，而且RMSE对绝对误差的离散程度容忍较小，个体绝对误差偏离均值将显著增加RMSE，因此RMSE倾向于减小绝对误差并使绝对误差尽可能均一化。 模型的绝对误差接近均一化，但是由于实际销量情况随时间是不平衡的，这就是造成smape差异的原因。
为估计2018年第一季度smape，作如下假设：
 SMAPE约等于销量绝对误差的平均值除以销量的平均值。即： $$SMAPE=\frac{1}{n} \sum_{i=1}^{n} \frac{|A_i-F_i|}{(|A_i|+|F_i|)/2} \approx \frac{\frac{1}{n} \sum_{i=1}^{n} |A_i-F_i|}{\frac{1}{n} \sum_{i=1}^{n} (|A_i|+|F_i|)/2} \approx \frac{\frac{1}{n} \sum_{i=1}^{n} |A_i-F_i|}{\frac{1}{n} \sum_{i=1}^{n} |A_i|}$$ 2018年第一季度销量平均值取自2013年第一季度、2014年第一季度、2015年第一季度、2016年第一季度、2017年第一季度销量平均值的最小二乘法线性插值。  smape计算
   时间 平均绝对误差[8] 平均销量[9] smape     2014q1 572.6247872118 39.097911[1] 14.645917711865364[3]   2015q1 574.5670977178 40.772911[1] 14.091883155407277[4]   2016q1 594.8380237664 44.137956[1] 13.476791353148277[5]   2017q1 609.</description>
    </item>
    
  </channel>
</rss>